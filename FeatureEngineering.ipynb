{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "   -In Machine Learning, a parameter is an internal variable of a model that is learned from the training data. For example, in linear regression, the slope and intercept are parameters that define the line that best fits the data. Parameters are adjusted during training to minimize error and improve the model's performance.\n",
        "    \n",
        "2. What is correlation? What does negative correlation mean?\n",
        "   -Correlation is a statistical measure that indicates the strength and direction of a linear relationship between two variables. A negative correlation means that as one variable increases, the other tends to decrease. For example, as temperature decreases, heating bills may increase.\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "   -Machine Learning is a field of artificial intelligence that enables systems to learn from data and improve over time without being explicitly programmed. The main components are data, features (input variables), model (algorithm), loss function (to measure error), and optimizer (to reduce error).\n",
        "   \n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "   -The loss value quantifies how far the model's predictions are from the actual outcomes. A low loss indicates accurate predictions and a better model, while a high loss shows that the model needs improvement. It's used during training to guide the optimization process.\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "   -Continuous variables can take any numeric value within a range, such as height, weight, or temperature. Categorical variables represent groups or categories, like gender (male/female), colors, or types of cuisine, and they are often non-numeric.\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "   -Categorical variables are usually converted into numerical format for use in ML models. Common techniques include label encoding (assigning a unique number to each category) and one-hot encoding (creating binary columns for each category). These help algorithms process and learn from the data correctly.\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "   -Training a dataset means using it to teach the model by adjusting its parameters based on input-output examples. Testing evaluates the trained model's performance on unseen data to measure how well it generalizes. This helps avoid overfitting and assess real-world performance.\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "   -sklearn.preprocessing is a module in the Scikit-learn library that provides tools for preparing and transforming data before feeding it into a model. It includes functions for scaling, encoding, imputing missing values, and normalizing features, which improve model efficiency and accuracy.\n",
        "\n",
        "9. What is a Test set?\n",
        "   -A test set is a portion of the dataset that is not used during training. After the model is trained, it is tested on this unseen data to evaluate its accuracy and generalizability. It simulates real-world performance on new inputs.\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        "   -In Python, we use train_test_split() from sklearn.model_selection to divide the dataset. Typically, 70–80% of the data is used for training and the rest for testing. A machine learning problem is approached through steps: understanding the problem, collecting and cleaning data, EDA, feature engineering, selecting a model, training, evaluation, and tuning.\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "   -Exploratory Data Analysis (EDA) helps understand the dataset’s structure, detect patterns, spot missing values or outliers, and assess relationships between variables. Performing EDA ensures that the data is clean and meaningful before applying models, improving model accuracy and reliability.\n",
        "\n",
        "12. What is correlation?\n",
        "   Correlation measures how closely two variables move in relation to each other. A high positive correlation indicates that both variables increase together, while a high negative correlation shows that one increases as the other decreases. It’s used to understand data dependencies.\n",
        "\n",
        "13. What does negative correlation mean?\n",
        "   Negative correlation means that as one variable increases, the other decreases. For example, the number of hours watching TV might negatively correlate with academic performance – more TV time could result in lower grades.\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "   -In Python, correlation can be found using the corr() function in pandas. For example, df.corr() on a DataFrame will return a matrix showing pairwise correlation values between all numerical columns. Visual tools like heatmaps can also help interpret it.\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "   -Causation implies that one variable directly affects another. Correlation only shows a relationship but not the cause. For instance, ice cream sales and drowning rates may be correlated (both rise in summer) but ice cream doesn’t cause drowning—summer is the real cause.\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "   -An optimizer is an algorithm that adjusts the model's parameters to minimize the loss function. Common types include:\n",
        "\n",
        "SGD (Stochastic Gradient Descent): Updates parameters using one data point at a time.\n",
        "\n",
        "Adam: Combines momentum and adaptive learning rate. Efficient for large datasets.\n",
        "\n",
        "RMSProp: Adapts learning rate based on recent gradients. Useful in RNNs.\n",
        "For example, optimizer = Adam() is used in neural networks to speed up training.\n",
        "\n",
        "17. What is sklearn.linear_model ?\n",
        "   -sklearn.linear_model is a module in Scikit-learn that contains linear models like Linear Regression, Logistic Regression, and Ridge/Lasso Regression. These models assume a linear relationship between input features and output and are easy to train and interpret.\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "   -model.fit() trains a model on given data. It requires at least two arguments: the feature set X and target labels y. It learns the relationship between inputs and outputs and stores the model parameters for prediction.\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?   \n",
        "   -model.predict() uses the trained model to make predictions on new data. It requires the input data X as an argument and returns predicted values based on learned patterns during training.\n",
        "\n",
        "20. What are continuous and categorical variables?\n",
        "   Continuous variables have numerical values that can take any value within a range (e.g., temperature, salary). Categorical variables represent distinct groups or classes (e.g., color, gender), often non-numeric and need encoding for ML models.\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "   -Feature scaling standardizes or normalizes the range of independent variables so that no feature dominates due to scale. It helps improve model convergence speed and accuracy, especially for algorithms like KNN, SVM, and gradient descent-based models.\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "   In Python, scaling is done using StandardScaler or MinMaxScaler from sklearn.preprocessing.\n",
        "\n",
        "23. What is sklearn.preprocessing?\n",
        "   - sklearn.preprocessing is a module in Scikit-learn for data preprocessing. It includes functions for feature scaling, encoding categorical variables, imputing missing values, and transforming data formats, ensuring the data is suitable for model training.\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "   -We use train_test_split() from sklearn.model_selection.\n",
        "\n",
        "25. Explain data encoding?\n",
        "   -Data encoding is the process of converting categorical variables into numerical format so that ML models can process them. Common methods include label encoding (assigns numbers to categories) and one-hot encoding (creates binary columns for each category). Encoding ensures that the model correctly interprets categorical data without assuming any inherent order unless it’s ordinal data.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZEwhjPw6Fb3S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TvwuslhFUkd"
      },
      "outputs": [],
      "source": []
    }
  ]
}